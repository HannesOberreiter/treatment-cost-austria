## Data Distribution

The distribution of the costs looks right skewed, with some outliers into the extreme highs. The two survey years look comparable, see fig. \@ref(fig:distr-year).  

```{r distr-year, include=T, messages=F, warnings=F, fig.cap="Violin and overlapping boxplot of the costs from the survey, extreme outliers are not visible."}
stats_data <- DATA %>% 
  group_by(year) %>% 
  summarise(
    max    = format(round(max(costs),2), nsmall = 2),
    mean   = format(round(mean(costs),2), nsmall = 2),
    median = format(round(median(costs),2), nsmall = 2),
    min    = format(round(min(costs),2), nsmall = 2)
    )

text <- paste0(
  "Max.: ", stats_data$max, "\n",
  "Min.: ", stats_data$min, "\n",
  "Mean: ", stats_data$mean, "\n",
  "Median: ", stats_data$median, "\n"
  )

ggplot(DATA) +
  geom_violin(
    aes(x = year, y = costs), 
    fill=colorBlindBlack8[7],
    color=colorBlindBlack8[7]
    ) +
  geom_boxplot(
    aes(x = year, y = costs), 
    outlier.shape = NA, alpha=0.5, fill=colorBlindBlack8[5]
    ) +
  geom_segment(
    x = 1, y = 45,
    xend = 1, yend = 52,
    lineend = "round",
    linejoin = "round",
    size = 0.5, 
    arrow = arrow(length = unit(0.1, "inches"))
  ) + 
  xlab("") + ylab("Cost / Colony [Euro]") +
  geom_segment(
    x = 2, y = 45,
    xend = 2, yend = 52,
    lineend = "round",
    linejoin = "round",
    size = 0.5, 
    arrow = arrow(length = unit(0.1, "inches"))
  ) + 
  annotate(
    "text",
    label = text,
    x = c(1.35, 2.35), y = c(40, 40),
    hjust = "right"
  ) + 
  theme_classic() +
  scale_y_continuous(
    limits = c(0,50),
    breaks = c(seq(0,50,5))
      )

```

Look at both survey years together we get the same picture, see fig. \@ref(fig:distr-plot).

```{r distr-plot, include=T, messages=F, fig.cap="Violin and overlapping boxplot of the costs from the survey, extreme outliers are not visible."}
stats_data <- DATA %>% 
  summarise(
    max    = format(round(max(costs),2), nsmall = 2),
    mean   = format(round(mean(costs),2), nsmall = 2),
    median = format(round(median(costs),2), nsmall = 2),
    min    = format(round(min(costs),2), nsmall = 2)
    )

text <- paste0(
  "Max.: ", stats_data$max, "\n",
  "Min.: ", stats_data$min, "\n",
  "Mean: ", stats_data$mean, "\n",
  "Median: ", stats_data$median, "\n"
  )

ggplot(DATA) +
  geom_violin(
    aes(x = "both survey years", y = costs), 
    fill=colorBlindBlack8[7],
    color=colorBlindBlack8[7]
    
    ) +
  geom_boxplot(
    aes(x = "both survey years", y = costs), 
    outlier.shape = NA, alpha=0.5, fill=colorBlindBlack8[5]
    ) +
  geom_segment(
    x = 1, y = 45,
    xend = 1, yend = 52,
    lineend = "round",
    linejoin = "round",
    size = 0.5, 
    arrow = arrow(length = unit(0.1, "inches"))
  ) + 
  xlab("") + ylab("Cost / Colony [Euro]") +
  annotate(
    "text",
    label = text,
    x = c(1.2), y = c(40),
    hjust = "right"
  ) + 
  theme_classic() +
  ylim(0, 50)
```



# Costs and Estimation

## Standard Costs

To calculate a standard value for data cleaning, we researched the official price in 2020 for several products and average usage amount by common beekeeping practices, see table \@ref(tab:standard-cost).

```{r standard-cost, include=T}
c <- "Our calculated estimates for treatment. Investments can be used long term (we calculate 10 years, eg. Hyperthermia) and are divided by the number of colonies. Material can also be used long term (~ 7 years, eg. Queen Cages) but needs to be bought for each colony. Consumables are used for each colony (eg. Formic Acid Long Term, 200ml)."
cn = c("Methode", "Investment", "Material", "Consumables")
knitr::kable(
  treatmentList[-1, c(3, 5:7)],
  booktabs = TRUE, row.names = FALSE, format="markdown",
  caption = c, col.names = cn
)
rm(c, cn)
```

## Compare Survey and Estimate

If we look at the results of the treatment costs in our survey and the with the estimates above, we can compare the results, see table \@ref(tab:summary). 

```{r summary, include=T}
c = "Table the total descriptive statistics for costs in our survey and estimates based on our standard cost estimates"

cs <- summary(DATA$costs)
es <- summary(DATA$t_estimated)

ct <- tibble(
  Type   = c("Survey", "Estimated"),
  min    = c(cs[1], es[1]),
  Q1     = c(cs[2], es[2]),
  Median = round(c(cs[3], es[3]), 2),
  Mean   = round(c(cs[4], es[4]), 2),
  Q3     = round(c(cs[5], es[5]), 2),
  Max    = c(cs[6], es[6])
)


knitr::kable(
  ct,
  booktabs = TRUE, row.names = FALSE,
  format = "markdown",
  caption = c
)

rm(c, cs, es, ct)

```

The most common treatment methods in our survey can be seen in table \@ref(tab:common).

```{r common, include=T}
# Get median number of colonies to calculate an estimate
m_colonies = median(DATA$hives_winter)

col <- DATA %>% 
    select(!!(paste0(treatmentList$ttotal, "12")))
# Get number of participates using the single treatment methods
sin <- col %>% 
    mutate(across(.cols = everything(), as.logical)) %>% colSums()
# get the average amount for number of months
nu <- col %>% na_if(0) %>% colMeans(na.rm=T)

common_single <- tibble(
  tname = treatmentList$tname,
  n = sin,
  p = round(sin*100/nrow(DATA),2),
  nu = round(nu, 2),
  est = round(treatmentList$investment / m_colonies + treatmentList$material + treatmentList$consumables*nu, 2)
) %>% arrange(desc(p))

c <- paste0("Most used Methods in the two survey years, average months indicating the average of months this methods was used. Estimated costs are calculated with ", m_colonies, " colonies, which represents the median number of colonies in our survey, and the average months of usage.")

cn = c("Method", "Total [n]", "Percent [%]", "Average Months[n]", "Estimated Costs")
knitr::kable(
  common_single,
  booktabs = TRUE, row.names = FALSE, format = "markdown",
  col.names = cn,
  caption = c
)
rm(cn, c, common_single, nu, sin, col, m_colonies)
```

The most common combinations, without Varroa Control and Drone Brood removal can be seen in table 
\@ref(tab:common-comb). The estimated costs are calculated for each beekeeper in the survey and then the average was taken as with the survey costs.

```{r common-comb, include=T, message=F}

DATA$t_desc_od <- str_replace(DATA$t_desc, "Drohnenbrutentnahme & ", "")
DATA$t_short_od <- str_replace(DATA$t_short, "Drohne & ", "")

d <- DATA %>% 
  group_by(t_short_od) %>% summarise(
    n     = n(),
    p     = round(n()*100/nrow(DATA),2),
    mc    = round(mean(costs), 2),
    medc  = round(median(costs), 2),
    me    = round(mean(t_estimated), 2),
    mede  = round(median(t_estimated), 2),
  ) %>% 
  filter(n >= 30) %>% arrange(desc(n))

c <- paste0("Most used combination with at least 30 participants, Mean and Median Costs from the survey and Estimated Costs in Euro.")

cn = c("Method", "Total [n]", "Percent [%]", "Cost Mean", "Cost Median", "Estimate Mean", "Estimate Median")

knitr::kable(
  d,
  booktabs = TRUE, row.names = FALSE,
  digits = 2,
  col.names = cn,
  caption = c,
)
rm(c, d)
```

## Linear Equation

To generate survey costs of treatments without combinations we used Linear Equation to solve for each single treatment. Did not work!

```{r linear-equation, include=T, warning = FALSE}

source("code-junks/LinearEquation.R", local = knitr::knit_global())
print(y)
rm(y)
```

## Bland-Altmann Plot

To check if our estimated in range with the survey, we use can use a bland-altmann plot, which compares the differences and shows if they are between our set confidence intervall (95%). For these plot we only use the mean prices with combinations of at least 15 beekeepers, see figure \@ref(fig:estimates-bland).

```{r estimates-bland, include=T, fig.cap="Bland-Altmann Plot with 95% Confidence Intervall, Mean difference between estimates and survey costs of the treatment combinations with at least 15 beekeepers." }
d <- DATA %>% 
  group_by(t_short_od) %>% summarise(
    n    = n(),
    p    = round(n()*100/nrow(DATA),2),
    mc   = round(mean(costs), 2),
    medc = round(median(costs), 2),
    me   = round(mean(t_estimated), 2),
    mede = round(median(t_estimated), 2),
  ) %>% 
  filter(n >= 15) %>% arrange(desc(n))

ba.stats <- bland.altman.stats(d$mc, d$me)

limit_y = round( ifelse( max(ba.stats$diffs) > (-1*min(ba.stats$diffs)), max(ba.stats$diffs), -1*min(ba.stats$diffs) ) + 0.5, digits = 1)

ggplot() +
  geom_point(aes(x = ba.stats$means, y = ba.stats$diffs, size = d$n)) +
  geom_abline(
    aes(
      intercept = ba.stats$lines, 
      colour = I(c(colorBlindBlack8[3], colorBlindBlack8[2], colorBlindBlack8[3])), 
      slope = c(rep(0, 3))),
    show.legend = F
    ) +
  geom_abline(
    aes(
      intercept = ba.stats$CI.lines, 
      color = I(c(rep(colorBlindBlack8[3], 2), rep(colorBlindBlack8[2], 2), rep(colorBlindBlack8[3], 2))),
      slope = c(rep(0, 6))
      ),
    linetype = "dashed",
    alpha = 0.5,
    show.legend = F
  ) +
  geom_hline(yintercept = 0, linetype = "dotted") +

  xlab("Means [Euro]") + ylab("Differences [Euro]") +
  labs(size = "Answers [n]") + 
  ylim(c( -1*limit_y, limit_y )) +
  theme_classic()

rm(d, ba.stats, limit_y)
```

## Conclusio

We can conclude that our estimates of treatment costs per colony are higher than calculated from the survey. Still the estimates are in range and not far off. 

# Operation Size

One question could be if bigger beekeeping operation spend less or more money on treatment. 

## Mean and Median

To test this we look at the cost distribution between different operation sizes, see fig. \@ref(fig:operation-size). The results indicate a bigger variance in the answers for the smaller hobby beekeepers, which could partly explained by the higher number of answers. The "1-20 Colonies" operations also have overall a higher mean and median cost answers. 

```{r operation-size, include=T, fig.cap="Mean and Median costs per colony in the survey for given Operation Size groups."}

K.SEQ <- c( seq( 0, 100, 20 ), Inf )
K.SEQ2 <- c( seq( 20, 120, 20 ), Inf )

V.LABEL <- paste(K.SEQ, K.SEQ2, sep = "-")
V.LABEL <- V.LABEL[1:6]
V.LABEL[6] <- "> 100"
V.LABEL[1] <- "1-20"

DATA$size_group <- cut( DATA$hives_winter, K.SEQ, labels=V.LABEL, include.lowest = TRUE, right = TRUE )

x <- DATA %>% group_by(size_group) %>% summarise(
  n       = n(),
  sm      = mean(costs),
  upper   = mean(costs)+sd(costs),
  lower   = mean(costs)-sd(costs),
  calc    = "Mean + Standard Deviation"
);

y <- DATA %>% group_by(size_group) %>% summarise(
  n       = n(),
  sm      = median(costs),
  upper   = quantile(costs)[4],
  lower   = quantile(costs)[2],
  calc    = "Median + 1 & 3 Quantile"
);

xy <- rbind(x, y)

ggplot(xy, aes(x = size_group, y = sm, ymin=lower, ymax=upper)) +
  geom_pointrange() + facet_wrap(~calc) +
  geom_text(aes(y=0, label = paste0("n=",n)), size=3) +
  xlab("Operation Size (Number of Colonies)") + ylab("Costs / Colony [Euro]") +
  theme_classic()
  
rm(y, x, K.SEQ, K.SEQ2)
```

## GLM Model

Next we want to check the results statistically with a regression model. To see what family we should use in the glm model, we use qq-plot to check for normality of costs, see \@ref(fig:operation-qq).

```{r operation-qq, include=T, fig.cap="QQ Plots of costs for the given operation size groups."}

ggplot(DATA, aes(sample=costs)) + 
  geom_qq() + geom_qq_line(color="red") + 
  theme_classic() + 
  facet_wrap(
    ~size_group, ncol = 3,
    labeller = labeller(
        size_group = function(x){return(paste(x, "Colonies"))}
      )
    )
```

The qqplots indicating a somewhat normal distribution and the previous shown boxplots, mean and median show a homogenity. 

```{r, indcude=T}
# We use normal parameters, same results as with lm
# ~ 0 to check not between groups
# https://www.researchgate.net/post/R_stats_It_is_possible_to_fix_the_intercept_of_a_GLS_model_with_both_categorical_and_continuous_predictors
# https://stats.stackexchange.com/questions/181113/is-there-any-difference-between-lm-and-glm-for-the-gaussian-family-of-glm
# https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use
# Poisson Info
# http://www.stat.cmu.edu/~brian/463-663/week04/checking-poissonness.pdf
# https://www.theanalysisfactor.com/generalized-linear-models-in-r-part-6-poisson-regression-count-variables/
# lmer package
# file:///Users/btree-mac/Downloads/v82i13.pdf

glm_size_gaussian <- glm(
  costs ~ 0 + size_group, data = DATA, family = gaussian()
  )
sum_size_gaussian <- summary(glm_size_gaussian)
sum_size_gaussian
```


```{r}
# Building Plot

# get CI
ci_size_gaussian  <- confint(glm_size_gaussian)
# Generate Tibble for easier plotting
size_gsm_plot = tibble(
  group = V.LABEL,
  mean = sum_size_gaussian$coefficients[,1],
  lower = ci_size_gaussian[,1],
  upper = ci_size_gaussian[,2]
)
# reorder plot
size_gsm_plot$group <- factor(size_gsm_plot$group, levels = V.LABEL)
# Post-hoc Pairwise
# Familiy-wise error correction, Bonferroni step down (Holm, FWER) 
costs_size_pairwise <- pairwise.t.test(DATA$costs, DATA$size_group, p.adj = c("holm"))
# Extract p-value
costs_size_pairwise <- costs_size_pairwise$p.value
# Generate dataframe for sign. plot
costs_size_pairwise <- 
  as_tibble(costs_size_pairwise) %>% 
  add_column(compare = rownames(costs_size_pairwise)) %>% 
  pivot_longer(., cols = c(1:5)) %>% 
  drop_na(value) %>% 
  filter(value < .05)

costs_size_pairwise$y <- max(size_gsm_plot$upper)+ seq(0.5,nrow(costs_size_pairwise), 1)

```


The resulting CI and pairwise comparison shows significant difference between the smallest group and bigger operation.

```{r operation-ci, include=T, fig.cap="Mean and confidence intervall for given operation size groups. Overall mean (orange line) and significance pairwise results are included."}
# Plot our Regression CI with Pairwise Sign.
ggplot(size_gsm_plot,
  aes(
    y = mean,
    x = group
  )) +
  geom_point() + geom_errorbar(aes(ymin = lower,
                                   ymax = upper)) + 
  theme_classic() + ylab("Costs [Euro]") + xlab("Operation Size [Number Colonies]") +
  #geom_text(aes(x = 3, y = 12.3, label="italic(p) < 0.05"), color = "gray", parse=T) + 
  annotate("text", x = 6, y = 10.3, label=paste("mean =", round(mean(DATA$costs),2)), color = "gray") + 
    geom_text(
      aes(
        x=c(1:6), y = 0, 
        label=paste("n = ", xy$n[1:6])), 
      color = "gray") + 
  geom_hline(yintercept=mean(DATA$costs), color=colorBlindBlack8[2]) +
  theme(
    axis.text.x = element_text(size = 14)
  ) +
  scale_y_continuous(
    limits = c(0,max(size_gsm_plot$upper)*1.3),
    breaks = c(0:round(max(size_gsm_plot$upper)*1.3))
      ) +
  geom_signif(
    data=costs_size_pairwise,
    aes(xmin=name, xmax=compare, annotations="italic(p) < 0.05", y_position = y),
    textsize = 3, vjust = -0.2, color = "gray", manual=TRUE, parse=TRUE)
rm(costs_size_pairwise, size_gsm_plot, sum_size_gaussian, glm_size_gaussian, xy)
```

## Conclusio

A trend can be seen, could be due to some high costs answers from very small beekeepers. Still there is a trend that bigger operations spend less money, but not significant.

# Estimated Economic Costs

## Generate Bootstrap CI

To generate a better estimate we use a confidence interval. The confidence interval is calculated with bootstrap method and 10.000 replicas. With the bootstrap samples we calculate a confidence interval based on Bca.

The Distribution of the bootstrap mean can be seen in fig. \@ref(fig:boot-mean).

```{r}
# Generate Bootstrap Dataset
#boot_median <- boot::boot(DATA$costs, fBootMedian, R=10000)
boot_mean   <- boot::boot(DATA$costs, fBootMean, R=10000)
#ci_median <- boot::boot.ci(boot_median, conf=0.95, type="bca")
ci_mean   <- boot::boot.ci(boot_mean, conf=0.95, type="bca")

fBootPlot <- function(x, t){
  p1 <- ggplot() + 
    geom_histogram(aes(x$t)) +
    geom_vline(xintercept=x$t0, color = colorBlindBlack8[2]) +
    geom_text(
      aes(x= x$t0+0.1, y = 1000, label = paste0(t, ": ", round(x$t0,2))),
      hjust="left",
      color = colorBlindBlack8[2]
      ) +
    theme_classic() + 
    xlab(paste("Cost -",t ,"[Euro]")) + ylab("Count [#]") + 
    ggtitle(paste(t,"- 10.000 Replicas"), subtitle = "Histogramm")
  
  p2 <- ggplot() + aes(sample=x$t) + 
    geom_qq() + geom_qq_line() +
    theme_classic() + ylab("Sample Quantiles (Costs)") + xlab("Theoretical Quantiles") +
    ggtitle("", subtitle = "QQ-Plot")
  
  return(p1 + p2)
}
```

```{r boot-mean, include=T, warning = F, fig.cap="Boostrap Mean"}
p <- fBootPlot(boot_mean, "Mean")
p
```

## Generating Regression CI

Another approach is to use a regression model, to calculate the CI.

```{r}
one.lm <- lm(costs ~ 1, data = DATA)
summary(one.lm)
confint(one.lm)
```


## Estimated Total Values in Austria

Marktwirtschaftlich müsste ich Kosten der Bienenvölker bzw. irgendwie die Volkanzahl * die Kosten



# Treatment

## Mixed Model

Generate Mixed Model to check if factor treatment type is relevant for costs.


# Links

- Science Forum: Ten common statistical mistakes to watch out for when writing or reviewing a manuscript
  - https://elifesciences.org/articles/48175
- What is the difference between fixed effect, random effect and mixed effect models?
  - https://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-and-mixed-effect-mode
- Check Your Residual Plots to Ensure Trustworthy Regression Results!
  - https://statisticsbyjim.com/regression/check-residual-plots-regression-analysis/
- ANOVA 
  - http://homepages.inf.ed.ac.uk/bwebb/statistics/ANOVA_in_R.pdf
- Varianzanalyse
  - https://www.beratung-statistik.de/statistik-beratung-infos/r-tutorial/r-varianzanalyse-post-hoc/


